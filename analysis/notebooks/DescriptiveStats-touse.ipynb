{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "import itertools\n",
    "import urllib\n",
    "\n",
    "# DB connections\n",
    "client = MongoClient()\n",
    "db = client.db_tasklog_clean\n",
    "# Collections\n",
    "User = db.user\n",
    "Log = db.log_chrome\n",
    "Labelled = db.data_labeled\n",
    "UserTasks = list(db.user_tasks.find({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive stats of user demographics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender groups:\n",
      "female 10\n",
      "male 13\n",
      "\n",
      "Age groups:\n",
      "18_24 11\n",
      "25_34 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gender groups\n",
    "print 'Gender groups:'\n",
    "for d in User.aggregate([{'$project': {'info.gender': 1}},\n",
    "        {'$group': {'_id': '$info.gender', 'count': {'$sum': 1}}}]):\n",
    "    print d['_id'], d['count']\n",
    "print\n",
    "    \n",
    "# Age groups\n",
    "print 'Age groups:'\n",
    "for d in User.aggregate([{'$project': {'info.age': 1}}, \n",
    "    {'$group': {'_id': '$info.age', 'count': {'$sum': 1}}}]):\n",
    "    print d['_id'], d['count']\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User computer technology experience: Median = 5.0 IQR = 1.0\n",
      "User Search engine experience: Median = 5.0 IQR = 1.0\n",
      "Frequency of using the experiment laptop for work: Median = 4.0 IQR = 1.0\n"
     ]
    }
   ],
   "source": [
    "allUsers = list(User.find({}))\n",
    "\n",
    "# Experience computer\n",
    "exp_comp = [int(a['info']['exp_comp']) for a in allUsers]\n",
    "iqr = np.percentile(exp_comp, 75) - np.percentile(exp_comp, 25)\n",
    "print 'User computer technology experience:', 'Median =', np.median(exp_comp), 'IQR =', iqr\n",
    "\n",
    "# Experience Search engine\n",
    "exp_se = [int(a['info']['exp_se']) for a in allUsers]\n",
    "iqr = np.percentile(exp_se, 75) - np.percentile(exp_se, 25)\n",
    "print 'User Search engine experience:', 'Median =', np.median(exp_se), 'IQR =', iqr\n",
    "\n",
    "# Frequency of work related usage of computer\n",
    "comp_work = [int(a['info']['comp_work']) for a in allUsers]\n",
    "iqr = np.percentile(comp_work, 75) - np.percentile(comp_work, 25)\n",
    "print 'Frequency of using the experiment laptop for work:', 'Median =', np.median(comp_work), 'IQR =', iqr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of using the experiment laptop:\n",
      "<25% : 1 ( 0.04 )\n",
      "25%-50% : 2 ( 0.09 )\n",
      "50%-75% : 1 ( 0.04 )\n",
      "75%-100% : 7 ( 0.30 )\n",
      "100% : 12 ( 0.52 )\n",
      "\n",
      "User search device preferences:\n",
      "always on computer : 3 ( 0.13 )\n",
      "mostly on computer : 15 ( 0.65 )\n",
      "half-half : 5 ( 0.22 )\n"
     ]
    }
   ],
   "source": [
    "total_users = float(len(list(allUsers)))\n",
    "\n",
    "# Frequency of using the experiment laptop\n",
    "comp_freq_labels = {'1': '<25%', '2':'25%-50%', '3': '50%-75%', '4': '75%-100%', '5': '100%'}\n",
    "comp_freq = User.aggregate([{'$project': {'info.freq_comp': 1}}, \n",
    "                           {'$group': {'_id': '$info.freq_comp', 'count': {'$sum': 1}}}, \n",
    "                           {'$sort': {'_id': 1}}])\n",
    "\n",
    "print 'Frequency of using the experiment laptop:'\n",
    "for f in comp_freq:\n",
    "    print comp_freq_labels[f['_id']], ':', f['count'], '(','%.2f'%(float(f['count'])/total_users), ')'\n",
    "print\n",
    "\n",
    "# Search device\n",
    "search_device_label = {'1': 'always on computer', '2': 'mostly on computer', \n",
    "                      '3': 'half-half', '4': 'mostly on mobile', '5': 'always on mobile'}\n",
    "search_device = User.aggregate([{'$project': {'info.search_device': 1}}, \n",
    "                                {'$group': {'_id': '$info.search_device', 'count': {'$sum': 1}}},\n",
    "                                {'$sort': {'_id': 1}}\n",
    "                               ])\n",
    "print 'User search device preferences:'\n",
    "for s in search_device:\n",
    "    if s['_id'] != None:   # Need to update Marc's registration form\n",
    "        print search_device_label[s['_id']], ':', s['count'], '(', '%.2f'%(float(s['count'])/total_users), ')'\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top searched informaiton types with computers: \n",
      "entertainment 18 0.78\n",
      "topic 18 0.78\n",
      "social 17 0.74\n",
      "fact 14 0.61\n",
      "news 14 0.61\n",
      "shopping 11 0.48\n",
      "task 10 0.43\n",
      "job 9 0.39\n",
      "routes 7 0.30\n",
      "travel 7 0.30\n",
      "person 6 0.26\n",
      "house 3 0.13\n",
      "\n",
      "Top searched information types with mobiles: \n",
      "social 18 0.78\n",
      "news 17 0.74\n",
      "routes 15 0.65\n",
      "entertainment 14 0.61\n",
      "fact 14 0.61\n",
      "topic 10 0.43\n",
      "task 9 0.39\n",
      "person 6 0.26\n",
      "shopping 5 0.22\n",
      "travel 2 0.09\n",
      "job 1 0.04\n"
     ]
    }
   ],
   "source": [
    "#Total number of users\n",
    "count_tot = float(len(list(allUsers)))\n",
    "\n",
    "# Top types of information searched on Mobile\n",
    "computer_search_for = [a['info']['computer_search_for'] for a in allUsers]\n",
    "computer_search_for = [s for sublist in computer_search_for for s in sublist]\n",
    "if a['info']['computer_search_for_other'] != '':\n",
    "    computer_search_for.append(a['info']['computer_search_for_other'])\n",
    "computer_search_for.sort()\n",
    "\n",
    "tot = []\n",
    "for k, g in itertools.groupby(computer_search_for):\n",
    "    tot.append((k, len(list(g))))\n",
    "tot.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print 'Top searched informaiton types with computers: '\n",
    "for t in tot:\n",
    "    print t[0], t[1], '%.2f'%(t[1]/count_tot)\n",
    "print\n",
    "    \n",
    "# Top types of information searched on Computer\n",
    "mobile_search_for = [a['info']['mobile_search_for'] for a in allUsers]\n",
    "mobile_search_for = [s for sublist in mobile_search_for for s in sublist]\n",
    "if a['info']['mobile_search_for_other'] != '':\n",
    "    mobile_search_for.append(a['info']['mobile_search_for_other'])\n",
    "mobile_search_for.sort()\n",
    "\n",
    "tot = []\n",
    "for k, g in itertools.groupby(mobile_search_for):\n",
    "    tot.append((k, len(list(g))))\n",
    "tot.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print \"Top searched information types with mobiles: \"\n",
    "for t in tot:\n",
    "    print t[0], t[1], '%.2f'%(t[1]/count_tot)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Descriptive stats of the log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "Data_stream = []\n",
    "for u in allUsers:\n",
    "    D =  list(Labelled.find({\"userid\": u['userid']}))[0]\n",
    "    data = D['data']\n",
    "    D_stream = []\n",
    "    for d in data:\n",
    "        tab_group = d['tab_group']\n",
    "        for ug in tab_group:\n",
    "            url_group = ug['url_group']\n",
    "            for e in url_group:\n",
    "                D_stream.append(e)\n",
    "    Data_stream.append((u['userid'], D_stream))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of tasks defined by users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "Number of user defined and annotated tasks: 291\n",
      "Number of tasks having subtasks: 17\n"
     ]
    }
   ],
   "source": [
    "main_tasks = list(itertools.ifilter(lambda x: x['task_level'] == 0, UserTasks))\n",
    "main_tasks = [str(t['_id']) for t in main_tasks]\n",
    "subtasks = list(itertools.ifilter(lambda x: x['task_level'] == 1, UserTasks))\n",
    "parent_tasks = []\n",
    "for s in subtasks:\n",
    "    parent_tasks.append(s['parent_task'])\n",
    "parent_tasks = list(set(parent_tasks))\n",
    "print len(parent_tasks)\n",
    "\n",
    "Filter = ['None', '000', '001', '002', '003', '004']\n",
    "# Not all tasks have been used to annotate data\n",
    "tasks = []\n",
    "p_tasks = []\n",
    "for u, data in Data_stream:\n",
    "    for e in data:\n",
    "        if e['taskid'] not in Filter:\n",
    "            tasks.append(e['taskid'])\n",
    "            if e['taskid'] in parent_tasks:\n",
    "                p_tasks.append(e['taskid'])\n",
    "                \n",
    "print 'Number of user defined and annotated tasks:', len(set(tasks))\n",
    "print 'Number of tasks having subtasks:', len(set(p_tasks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of tasks analyzed in postQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tasks analysed in postQ: 135\n"
     ]
    }
   ],
   "source": [
    "# Total number of tasks being analyzed in postQ\n",
    "chosen_tasks = []\n",
    "for u in allUsers:\n",
    "    postQ = u.get('postQ', {})\n",
    "    tasklist = postQ.get('tasklist', [])\n",
    "    for t in tasklist:\n",
    "        if t['chosen'] == True:\n",
    "            chosen_tasks.append(t)\n",
    "print 'Number of tasks analysed in postQ:', len(chosen_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of days, queries issued and annotated, pages visited and annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days in the experiment:  min: 2 max: 11 mean: 6.0\n"
     ]
    }
   ],
   "source": [
    "# Number of days\n",
    "days = []\n",
    "for u, data in Data_stream:\n",
    "    data.sort(key = lambda x: x['timestamp_bson'])\n",
    "    # Find days that actually have data\n",
    "    dates = [d['timestamp_bson'].date() for d in data]\n",
    "    days.append(len(set(dates)))\n",
    "print \"Number of days in the experiment: \", 'min:', min(days), 'max:', max(days), 'mean:', np.median(days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of queries annotated:  2626\n",
      "Total number of queries annotated with user defined tasks: 1808\n"
     ]
    }
   ],
   "source": [
    "# Number of queries\n",
    "num_q = 0\n",
    "# Number of queries annotated with user defined tasks\n",
    "num_q_userdefine = 0\n",
    "for u, data in Data_stream:\n",
    "    q = itertools.ifilter(lambda x: x['event'] in ['tab-search-new', 'tab-search-verticle'] \n",
    "                          and not x['taskid'] == 'None', data)\n",
    "    q1 = itertools.ifilter(lambda x: x['event'] in ['tab-search-new', 'tab-search-verticle'] \n",
    "                          and not x['taskid'] in ['None', '000', '001', '002', '003', '004'], data)\n",
    "    num_q += len(list(q))\n",
    "    num_q_userdefine += len(list(q1))\n",
    "print 'Total number of queries annotated: ', num_q\n",
    "print 'Total number of queries annotated with user defined tasks:', num_q_userdefine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pages annotated: 32902\n",
      "Total number of pages annotated with user defined tasks: 17313\n"
     ]
    }
   ],
   "source": [
    "# Number of pages annotated - Does not consider how long the user actually stayed on the page, \n",
    "# only count loaded pages that have been annotated\n",
    "# It also includes those propagated labeles\n",
    "num_p = 0\n",
    "num_p_userdefine = 0\n",
    "for u, data in Data_stream:\n",
    "    p = itertools.ifilter(lambda x: x['event'] == 'tab-loaded' and not x['taskid'] == 'None', data)\n",
    "    num_p += len(list(p))\n",
    "    p1 = itertools.ifilter(lambda x: x['event'] == 'tab-loaded' and not x['taskid'] in ['None', \n",
    "                                '000', '001', '002', '003', '004'], data)\n",
    "    num_p_userdefine += len(list(p1))\n",
    "print 'Total number of pages annotated:', num_p\n",
    "print 'Total number of pages annotated with user defined tasks:', num_p_userdefine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do not use the result of the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engines:\n",
      " 242\n",
      "bing 27\n",
      "google 3823\n",
      "yahoo 3\n",
      "\n",
      "Media:\n",
      " 242\n",
      "apps 1\n",
      "flights 2\n",
      "images 386\n",
      "maps 21\n",
      "news 40\n",
      "shopping 1\n",
      "videos 11\n",
      "web 3391\n",
      "\n",
      "Page:\n",
      "0 3765\n",
      "10 51\n",
      "11 1\n",
      "20 17\n",
      "30 9\n",
      "40 4\n",
      "50 2\n",
      "60 2\n",
      "70 1\n",
      "80 1\n",
      " 242\n"
     ]
    }
   ],
   "source": [
    "X = Log.aggregate([{'$match': {'event': 'tab-search'}}, \n",
    "                         {'$project':{\n",
    "                                'engine': '$details.engine',\n",
    "                                'media': '$details.media',\n",
    "                                'start': '$details.start',\n",
    "                            }},\n",
    "                         ])\n",
    "X = list(X)\n",
    "E = [x.get('engine', '') for x in X]\n",
    "M = [x.get('media', '') for x in X]\n",
    "S = [x.get('start', '') for x in X]\n",
    "E.sort()\n",
    "M.sort()\n",
    "S.sort()\n",
    "print 'Engines:'\n",
    "for k, g in itertools.groupby(E):\n",
    "    print k, len(list(g))\n",
    "print\n",
    "print 'Media:'\n",
    "for k, g in itertools.groupby(M):\n",
    "    print k, len(list(g))\n",
    "print\n",
    "print 'Page:'\n",
    "for k, g in itertools.groupby(S):\n",
    "    print k, len(list(g))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
